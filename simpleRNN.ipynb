{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Size\n",
    "\n",
    "maxFeatures = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = maxFeatures)\n",
    "print(f'Training Data Shape: {X_train.shape}, Training Labels Shape: {y_train.shape}')\n",
    "print(f'Testing Data Shape: {X_test.shape}, Testing Labels Shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Review and Label\n",
    "\n",
    "sampleReview    = X_train[0]\n",
    "sampleLabel     = y_train[0]\n",
    "\n",
    "print(f'Sample Review (as integers): {sampleReview}')\n",
    "print(f'Sample Label  (as integers): {sampleLabel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all the word indexes to words\n",
    "\n",
    "wordIndex = imdb.get_word_index()\n",
    "wordIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverseWordIndex = {value: key for key, value in wordIndex.items()}\n",
    "reverseWordIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referring the documentation to decode IMDB dataset reviews \n",
    "\n",
    "decodedReview = ' '.join([reverseWordIndex.get(i - 3,'?') for i in sampleReview])\n",
    "decodedReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Use for sequence for pre-padding\n",
    "\n",
    "maxLength = 500\n",
    "\n",
    "X_train = sequence.pad_sequences(\n",
    "    X_train,\n",
    "    maxlen = maxLength\n",
    ")\n",
    "\n",
    "X_test  = sequence.pad_sequences(\n",
    "    X_test,\n",
    "    maxlen = maxLength\n",
    ")\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDimensions = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model and Embedding Layer\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "    maxFeatures, \n",
    "    maxDimensions, \n",
    "    input_length = maxLength\n",
    "))\n",
    "\n",
    "model.add(\n",
    "    SimpleRNN(\n",
    "    maxDimensions, \n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "model.add(Dense(\n",
    "    1, \n",
    "    activation = \"sigmoid\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Early Stopping Callback\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    patience = 5,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "earlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with Early Stopping Callback\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs = 20, \n",
    "    batch_size = 32, \n",
    "    validation_split = 0.2, \n",
    "    callbacks = [earlyStopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the Model File\n",
    "\n",
    "model.save('simpleRNN-IMDB.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
